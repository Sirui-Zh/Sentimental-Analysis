{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oot9_4C4wFo5"
      },
      "source": [
        "<h2>CS 3780/5780 Creative Project: </h2>\n",
        "<h3>Emotion Classification of Natural Language</h3>\n",
        "\n",
        "Names and NetIDs for your group members: Sirui Zhang(sz694), Sheng Zhang(sz696)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N4PmL5jwFo7"
      },
      "source": [
        "<h3>Introduction:</h3>\n",
        "\n",
        "<p> The creative project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The past programming projects provide templates for how to do this (and you can reuse part of your code if you wish), and the lectures provide some of the methods you can use. So, this creative project brings realism to how you will use machine learning in the real world.  </p>\n",
        "\n",
        "The task you will work on is classifying texts to human emotions. Through words, humans express feelings, articulate thoughts, and communicate our deepest needs and desires. Language helps us interpret the nuances of joy, sadness, anger, and love, allowing us to connect with others on a deeper level. Are you able to train an ML model that recognizes the human emotions expressed in a piece of text? <b>Please read the project description PDF file carefully and follow the instructions there. Also make sure you write your code and answers to all the questions in this Jupyter Notebook </b> </p>\n",
        "<p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VandyT-vwFo8"
      },
      "source": [
        "<h2>Part 0: Basics</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTAziU1fwFo9"
      },
      "source": [
        "<h3>0.1 Import:</h3><p>\n",
        "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
        "    \n",
        "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
        "    \n",
        "https://pytorch.org/tutorials/\n",
        "    \n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Icet68wFo9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "# TODO\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL7GDx1dwFo-"
      },
      "source": [
        "<h3>0.2 Accuracy and Mean Squared Error:</h3><p>\n",
        "To measure your performance in the Kaggle Competition, we are using accuracy. As a recap, accuracy is the percent of labels you predict correctly. To measure this, you can use library functions from sklearn. A simple example is shown below.\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szZUfrCcwFo_",
        "outputId": "e6160a7b-a635-4607-bad5-f53fc2c3ca56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42857142857142855"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = [3, 2, 1, 0, 1, 2, 3]\n",
        "y_true = [0, 1, 2, 3, 1, 2, 3]\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svrw1peEwFpA"
      },
      "source": [
        "<h2>Part 1: Basic</h2><p>\n",
        "Note that your code should be commented well and in part 1.4 you can refer to your comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciBN3q7xwFpA"
      },
      "source": [
        "<h3>1.1 Load and preprocess the dataset:</h3><p>\n",
        "We provide how to load the data on Kaggle's Notebook.\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2BfDR5xwFpB"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "train_text = train[\"text\"]\n",
        "train_label = train[\"label\"]\n",
        "\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "test_id = test[\"id\"]\n",
        "test_text = test[\"text\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3g55vaywFpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ce23ba-2705-41cd-b5d5-62f836736e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Training Data:\n",
            "                                      processed_text  label\n",
            "0  interact daily basis either real life online v...      1\n",
            "1  stranger fiction cant even begin comprehend po...      1\n",
            "2                   sit aftermath feeling damn alone      1\n",
            "3                                      great job hat     25\n",
            "4  hate thread posted people whining feel wronged...      9\n",
            "\n",
            "Processed Testing Data:\n",
            "   id                                     processed_text\n",
            "0   0                   im feeling like hot potato right\n",
            "1   1  feel becoming impressed upon little year old h...\n",
            "2   2    id ever held girl hand boy sure feel triumphant\n",
            "3   3  feel thats feel grief brave thought lost life ...\n",
            "4   4       feel never resolved way keep everybody happy\n"
          ]
        }
      ],
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
        "# TODO\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define the text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenize the text (split into words)\n",
        "    words = text.split()\n",
        "    # Remove stopwords and apply lemmatization\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    # Rejoin words into a single string\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing to the text columns\n",
        "train['processed_text'] = train['text'].apply(preprocess_text)\n",
        "test['processed_text'] = test['text'].apply(preprocess_text)\n",
        "\n",
        "# Save the processed data to new CSV files\n",
        "train[['processed_text', 'label']].to_csv(\"train_processed.csv\", index=False)\n",
        "test[['id', 'processed_text']].to_csv(\"test_processed.csv\", index=False)\n",
        "\n",
        "# Print the first few rows of the processed data for verification\n",
        "print(\"Processed Training Data:\")\n",
        "print(train[['processed_text', 'label']].head())\n",
        "\n",
        "print(\"\\nProcessed Testing Data:\")\n",
        "print(test[['id', 'processed_text']].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "X = train['processed_text']\n",
        "y = train['label']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1libAu4kElI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_IQRByzwFpC"
      },
      "source": [
        "<h3>1.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
        "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NcGUyBwFpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912b0570-b3a5-4f3f-c878-ff86f48c6de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.75      0.91      0.83       455\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00        16\n",
            "           4       0.85      0.64      0.73       183\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.00      0.00      0.00        11\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.00      0.00      0.00        26\n",
            "           9       0.87      0.61      0.72       224\n",
            "          10       0.00      0.00      0.00        25\n",
            "          11       0.00      0.00      0.00        17\n",
            "          12       0.30      0.68      0.41       157\n",
            "          13       0.00      0.00      0.00         3\n",
            "          14       0.00      0.00      0.00        11\n",
            "          15       0.00      0.00      0.00        16\n",
            "          16       0.65      0.26      0.37        50\n",
            "          17       0.00      0.00      0.00        45\n",
            "          18       0.64      0.37      0.47        19\n",
            "          19       0.00      0.00      0.00        12\n",
            "          20       1.00      0.09      0.17        11\n",
            "          21       0.67      0.93      0.78       468\n",
            "          22       0.64      0.43      0.51        21\n",
            "          23       0.00      0.00      0.00        13\n",
            "          24       0.00      0.00      0.00        28\n",
            "          25       0.67      0.14      0.23        44\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.81      0.53      0.64       128\n",
            "\n",
            "    accuracy                           0.66      2000\n",
            "   macro avg       0.28      0.20      0.21      2000\n",
            "weighted avg       0.63      0.66      0.62      2000\n",
            "\n",
            "Accuracy Score:\n",
            "0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
        "# TODO\n",
        "# Convert text data into TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logistic_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = logistic_model.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "print(\"Accuracy Score:\")\n",
        "print(accuracy_score(y_val, y_val_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Step 1: Preprocess the test dataset using the same TF-IDF vectorizer\n",
        "test_tfidf = tfidf_vectorizer.transform(test['text'])  # Ensure test['text'] exists in your test dataset\n",
        "\n",
        "# Step 2: Make predictions on the test dataset\n",
        "test_predictions = logistic_model.predict(test_tfidf)\n",
        "\n",
        "# Step 3: Create a DataFrame with the results\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],          # Use the 'id' column from your test dataset\n",
        "    'label': test_predictions  # Predicted labels\n",
        "})\n",
        "\n",
        "# Step 4: Save the predictions to a CSV file\n",
        "submission.to_csv('logistic_regression_submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'logistic_regression_submission.csv'.\")\n",
        "files.download('logistic_regression_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IgVQ4aPPDio0",
        "outputId": "aef7518b-f7c6-4cdd-defe-bf290d817162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'logistic_regression_submission.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85d7af91-58c5-4e5f-b2a7-55bf05cf9bb0\", \"logistic_regression_submission.csv\", 117969)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck7db-RlwFpC"
      },
      "source": [
        "<h3>1.3 Training, Validation and Model Selection:</h3><p>\n",
        "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGns_FD_wFpC"
      },
      "outputs": [],
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 1.4\n",
        "# TODO\n",
        "\n",
        "# Already did in Part 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DPsCASRwFpD"
      },
      "source": [
        "<h3>1.4 Explanation in Words:</h3><p>\n",
        "    You need to answer the following questions in the markdown cell after this cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcKcdFSWwFpD"
      },
      "source": [
        "1.4.1 How did you formulate the learning problem?\n",
        "\n",
        "1.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
        "\n",
        "1.4.3 How did you do the model selection?\n",
        "\n",
        "1.4.4 Does the test performance reach the first baseline \"Tiny Piney\"? (Please include a screenshot of Kaggle Submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.1:\n",
        "\n",
        "I formulated the learning problem as a supervised text classification task where the goal was to predict the type of emotion expressed in a sentence. The input data, which consisted of processed text, was converted into numerical features using the TF-IDF vectorization technique to highlight the importance of words. The target output was a set of predefined emotion labels. I treated this as a multi-class classification problem and used logistic regression as the main model to learn the relationship between the features and the labels. The model was trained on labeled data, and its performance was evaluated using metrics like accuracy and classification reports to ensure it effectively captured the emotional tone of the sentences.\n",
        "\n",
        "1.4.2: Logistic Regression:\n",
        "\n",
        "Why Chosen: Logistic Regression is a simple and interpretable linear model that works well on text data when combined with feature extraction techniques like TF-IDF. Its computational efficiency and strong baseline performance on high-dimensional data make it a reliable first choice.\n",
        "How It Was Used: Trained on TF-IDF-transformed features to predict sentiment labels.\n",
        "\n",
        "1.4.3:\n",
        "\n",
        "\n",
        "For model selection, I experimented with different algorithms to see which one performed best on the validation set. After preprocessing the text data using TF-IDF, I trained and evaluated models like logistic regression and compared them to alternatives like Naive Bayes or SVM. I used metrics such as accuracy, precision, recall, and F1-score to assess their performance. Based on these evaluations, I chose the model that provided the best balance between performance and efficiency. Additionally, I fine-tuned hyperparameters, such as regularization strength and the number of iterations, to ensure the model performed as effectively as possible.\n",
        "\n",
        "1.4.4"
      ],
      "metadata": {
        "id": "Sj88MvYUqss_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AUjRSmqwFpD"
      },
      "source": [
        "<h2>Part 2: Be creative!</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34JfeIwCwFpD"
      },
      "source": [
        "<h3>2.1 Open-ended Code:</h3><p>\n",
        "You may follow the steps in part 1 again but making innovative changes like using new training algorithms, etc. Make sure you explain everything clearly in part 2.2. Note that beating \"Zero Hero\" is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6iTq5kZwFpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ab76a9-71fa-4bc5-9423-4911d2737760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0: 100%|██████████| 500/500 [23:56<00:00,  2.87s/it, loss=1.31]\n",
            "Epoch 1: 100%|██████████| 500/500 [23:21<00:00,  2.80s/it, loss=1.24]\n",
            "Epoch 2: 100%|██████████| 500/500 [23:11<00:00,  2.78s/it, loss=0.633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.88      0.95      0.91       455\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00        16\n",
            "           4       0.84      0.85      0.85       183\n",
            "           5       0.00      0.00      0.00         6\n",
            "           6       0.00      0.00      0.00        11\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.12      0.27      0.17        26\n",
            "           9       0.87      0.81      0.84       224\n",
            "          10       0.09      0.04      0.06        25\n",
            "          11       0.00      0.00      0.00        17\n",
            "          12       0.38      0.65      0.48       157\n",
            "          13       0.00      0.00      0.00         3\n",
            "          14       0.00      0.00      0.00        11\n",
            "          15       0.00      0.00      0.00        16\n",
            "          16       0.62      0.64      0.63        50\n",
            "          17       0.21      0.07      0.10        45\n",
            "          18       0.64      0.47      0.55        19\n",
            "          19       0.00      0.00      0.00        12\n",
            "          20       1.00      0.36      0.53        11\n",
            "          21       0.85      0.91      0.88       468\n",
            "          22       0.63      0.81      0.71        21\n",
            "          23       0.00      0.00      0.00        13\n",
            "          24       0.60      0.21      0.32        28\n",
            "          25       0.47      0.57      0.52        44\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.89      0.71      0.79       128\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.32      0.30      0.30      2000\n",
            "weighted avg       0.72      0.74      0.72      2000\n",
            "\n",
            "Accuracy Score:\n",
            "0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 2.2\n",
        "# TODO\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv(\"/train.csv\")\n",
        "test = pd.read_csv(\"/test.csv\")\n",
        "\n",
        "# Preprocessing\n",
        "X_train, X_val, y_train, y_val = train_test_split(train['text'], train['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Initialize BERT tokenizer and model\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(set(train['label'])))\n",
        "\n",
        "# Step 3: Create PyTorch datasets and dataloaders\n",
        "MAX_LEN = 32  # Reduce sequence length for faster processing\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, MAX_LEN)\n",
        "val_dataset = TextDataset(X_val.tolist(), y_val.tolist(), tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Step 4: Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Step 5: Training Loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 3  # Reduced epochs\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# Step 6: Validation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "print(\"Accuracy Score:\")\n",
        "print(accuracy_score(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Inference on test dataset\n",
        "test_dataset = TextDataset(test['text'].tolist(), [0]*len(test), tokenizer, MAX_LEN)  # Dummy labels for test set\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# Save predictions\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'label': test_preds\n",
        "})\n",
        "submission.to_csv('bert_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "vbHEh3pSC-YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('bert_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "t-pOO-4BUDMG",
        "outputId": "aecdadb4-e46d-491a-c46e-8487681c30b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41aaf687-187f-465d-b1be-284ede8c6524\", \"distilbert_submission.csv\", 117241)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avROLHctwFpE"
      },
      "source": [
        "<h3>2.2 Explanation in Words:</h3><p>\n",
        "You need to answer the following questions in a markdown cell after this cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agabn-xhwFpE"
      },
      "source": [
        "2.2.1 How much did you manage to improve performance on the test set? Did you beat \"Zero Hero\" in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
        "\n",
        "2.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.1:\n",
        "\n",
        "Using BERT, I significantly improved the performance on the test set and successfully beat the \"Zero Hero\" baseline on Kaggle. By fine-tuning BERT on the emotion classification dataset, I leveraged its powerful language understanding to achieve much better predictions compared to simpler models. The improvement was evident in the accuracy score, which surpassed the baseline submission on Kaggle.\n",
        "\n",
        "2.2.2:\n",
        "To achieve this, I utilized BERT for its advanced contextual language understanding and fine-tuned it for the emotion classification task. Here's what I did:\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "The dataset was split into training and validation sets to allow reliable evaluation of the model's performance.\n",
        "The text data was tokenized using the BertTokenizer from Hugging Face. I used padding and truncation to ensure uniform input lengths (MAX_LEN = 32), which helped maintain computational efficiency.\n",
        "Dataset Preparation:\n",
        "\n",
        "I implemented a TextDataset class to format the data for PyTorch. The class included tokenized input features (input_ids and attention_mask) and the corresponding labels.\n",
        "PyTorch DataLoaders were used to create batches for training and validation to handle the data efficiently.\n",
        "Fine-Tuning BERT:\n",
        "\n",
        "I used the pre-trained bert-base-uncased model and added a classification head to match the number of emotion labels in the dataset.\n",
        "Fine-tuning was performed using the AdamW optimizer with a learning rate of 2e-5, which is well-suited for transformer models.\n",
        "To prevent overfitting and improve efficiency, I trained the model for 3 epochs and monitored the loss during training.\n",
        "Training Process:\n",
        "\n",
        "The training loop involved feeding batches of tokenized text into the model and calculating the loss using cross-entropy.\n",
        "I performed backpropagation to update the model weights while using the GPU to speed up computations.\n",
        "Validation and Metrics:\n",
        "\n",
        "During validation, I evaluated the model in evaluation mode to generate predictions without updating weights.\n",
        "Predictions were compared against the true labels, and metrics such as accuracy, precision, recall, and F1-score were calculated to assess performance.\n",
        "Why I Used BERT:\n",
        "\n",
        "BERT is a state-of-the-art transformer model pre-trained on a large corpus, making it capable of capturing the context and nuances in text better than traditional models.\n",
        "Its bidirectional nature allows it to understand both preceding and succeeding words in a sentence, which is crucial for identifying emotions.\n",
        "Outcome:\n",
        "\n",
        "The fine-tuned BERT model significantly outperformed the baseline, as reflected in the evaluation metrics and the Kaggle leaderboard. Its ability to learn from pre-trained embeddings and adapt to the specific task of emotion classification made it a game-changer."
      ],
      "metadata": {
        "id": "KI5sJtqdSZsg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZTbWUkwFpE"
      },
      "source": [
        "<h2>Part 3: Kaggle Submission</h2><p>\n",
        "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The results should be presented in two columns in csv format: the first column is the data id (0-14999) and the second column includes the predictions for the test set. The first column must be named id and the second column must be named label (otherwise your submission will fail). A sample predication file can be downloaded from Kaggle for each problem.\n",
        "We provide how to save a csv file if you are running Notebook on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu0vnJDnwFpE"
      },
      "outputs": [],
      "source": [
        "id = range(15000)\n",
        "prediction = range(15000)\n",
        "submission = pd.DataFrame({'id': id, 'label': prediction})\n",
        "submission.to_csv('/kaggle/working/submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExvaK1EfwFpE"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "\n",
        "# You may use pandas to generate a dataframe with country, date and your predictions first\n",
        "# and then use to_csv to generate a CSV file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYcvtnZ4wFpF"
      },
      "source": [
        "<h2>Part 4: Resources and Literature Used</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "915GgTGnwFpF"
      },
      "source": [
        "Please cite the papers and open resources you used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0Pvh6MwFpF"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}